{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6085f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "imdb_file = 'IMDB Dataset.csv'\n",
    "df=pd.read_csv(imdb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'taille de mon data frame {df.shape}')\n",
    "print(f'nom des colonnes {list(df.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d700f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "row=3\n",
    "print(df['review'][row])\n",
    "print(df['sentiment'][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d8168",
   "metadata": {},
   "source": [
    "## nettoyer les balises html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_tools import remove_html_tags\n",
    "\n",
    "clean_text=remove_html_tags(df['review'][row])\n",
    "print(\"AVANT NETTOYAGE:\")\n",
    "print(df['review'][row])\n",
    "print(\"APRES NETTOYAGE:\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffe2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"]=df[\"review\"].apply(lambda x:remove_html_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map={'positive':[1,0], 'negative':[0,1]}\n",
    "print(sentiment_map['positive'])\n",
    "print(sentiment_map['negative'])\n",
    "df[\"sentiment\"]=df[\"sentiment\"].apply(lambda x:sentiment_map[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4528e94",
   "metadata": {},
   "source": [
    "## Séparer la base de données en ensemble d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a859151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_rate=0.80\n",
    "dataset_size=df.shape[0]\n",
    "train_size=int(train_rate*dataset_size)\n",
    "print(f\"Taille de la base de données {dataset_size} de l'ensemble d'apprentissage {train_size} et de test {dataset_size-train_size}\")\n",
    "\n",
    "# Tirer au hasard les indices de train\n",
    "train_indices=np.random.choice(dataset_size,train_size, replace=False)\n",
    "train_indices=sorted(train_indices)\n",
    "\n",
    "# Collecter dans les indices de test les indices qui ne sont pas dans le train\n",
    "train_indices_dict = {n:n for n in train_indices}\n",
    "test_indices=[]\n",
    "for n in range(dataset_size):\n",
    "    try:\n",
    "        train_indices_dict[n]\n",
    "    except:\n",
    "        test_indices.append(n)\n",
    "        \n",
    "df_train=df.iloc[train_indices]\n",
    "df_test=df.iloc[test_indices]\n",
    "\n",
    "print(f\"Taille de l'ensemble de train {df_train.shape[0]}\")\n",
    "print(f\"Taille de l'ensemble de test {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767435af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(df.review,df.sentiment,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28612f7e",
   "metadata": {},
   "source": [
    "## Pretraiter les review pour les transformer en entier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words = 20000\n",
    "oov_token = '<unk>'\n",
    "max_length=1000\n",
    "pad_type='post'\n",
    "trunc_type='post'\n",
    "tokenizer = Tokenizer(num_words=num_words,oov_token=oov_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae667db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews=list(x_train)\n",
    "tokenizer.fit_on_texts(train_reviews)\n",
    "train_sequences=tokenizer.texts_to_sequences(train_reviews)\n",
    "train_padded=pad_sequences(train_sequences,padding=pad_type,truncating=trunc_type,maxlen=max_length)\n",
    "train_labels=list(y_train)\n",
    "\n",
    "test_reviews=list(x_test)\n",
    "test_sequences=tokenizer.texts_to_sequences(test_reviews)\n",
    "test_padded=pad_sequences(test_sequences,padding=pad_type,truncating=trunc_type,maxlen=max_length)\n",
    "test_labels=list(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f508883",
   "metadata": {},
   "source": [
    "## Implementer le classifieur avec tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f999961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def create_model_seq_api(vocab_size,embedding_dim,hidden_layer_dims,max_length):\n",
    "    \"\"\"\n",
    "    create model using sequential API\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,embedding_dim,input_length=max_length))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for dim in hidden_layer_dims:\n",
    "        model.add(Dense(dim,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "vocab_size=len(tokenizer.word_index)\n",
    "word_embedding_dim=16\n",
    "hidden_layer_dims=[100]\n",
    "\n",
    "model=create_model_seq_api(vocab_size=vocab_size,\n",
    "                           embedding_dim=word_embedding_dim,\n",
    "                           hidden_layer_dims=hidden_layer_dims,\n",
    "                           max_length=max_length)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "summary=model.fit(train_padded,np.array(train_labels),epochs=2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_padded,np.array(test_labels),verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8e88cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b182b2c1b7f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "prediction=model.predict([test_padded[0]])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d957f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
